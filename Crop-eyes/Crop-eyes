# Per prima cosa installo mediapipe
!pip install mediapipe

# Poi scarico i pacchetti dei modelli.
# Nella documentazione di MediaPipe vi sono ulteriori informazioni su questi bundle di modelli
!wget -O face_landmarker_v2_with_blendshapes.task -q https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task

# Qui importo tutto quello che mi serve

from mediapipe import solutions
import mediapipe as mp
from mediapipe.framework.formats import landmark_pb2
import numpy as np
import cv2
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow  # Questo mi serve per visualizzare l'immagine
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
from PIL import Image
from re import I
from google.colab import drive
import os

# Prendo l'immagine
drive.mount('/content/drive')

# Percorso del file su Google Drive
file = '/content/drive/MyDrive/Tirocinio/frame1.jpg'

# Creo la funzione draw_landmarks_on_image che mi disegna sull'immagine i landmark riconosciuti sull'iride
# La funzione ritorna l'immagine già con i landmark disegnati
def draw_landmarks_on_image(rgb_image, detection_result):
  face_landmarks_list = detection_result.face_landmarks
  annotated_image = np.copy(rgb_image)

  # Qui si passano in rassegna i volti rilevati nell'immagine per visualizzarli.
  for idx in range(len(face_landmarks_list)):
    face_landmarks = face_landmarks_list[idx]

    # Qui vengono disegnati i landmark sulle iridi
    face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()
    face_landmarks_proto.landmark.extend([ landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks ])

    solutions.drawing_utils.draw_landmarks(
        image=annotated_image,
        landmark_list=face_landmarks_proto,
        connections=mp.solutions.face_mesh.FACEMESH_IRISES,
          landmark_drawing_spec=None,
          connection_drawing_spec=mp.solutions.drawing_styles
          .get_default_face_mesh_iris_connections_style())

  return annotated_image

# Successivamente, inizio con i passaggi per il riconoscimento dei landmark
# Passaggio 1 --> Crea un oggetto FaceLandmarker
base_options = python.BaseOptions(model_asset_path='face_landmarker_v2_with_blendshapes.task')
options = vision.FaceLandmarkerOptions(base_options=base_options,
                                       output_face_blendshapes=True,
                                       output_facial_transformation_matrixes=True,
                                       num_faces=1)
detector = vision.FaceLandmarker.create_from_options(options)

# Passaggio 2 --> Carica una immagine in input
image = mp.Image.create_from_file(file)

# Passaggio 3 --> Rileva tutti i punti di riferimento del viso dall'immagine data in input
detection_result = detector.detect(image)

# Passaggio 4 --> Elaborare il risultato del rilevamento, per poi visualizzarlo
annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)
cv2_imshow(cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))

mp_drawing = mp.solutions.drawing_utils
mp_face_mesh = mp.solutions.face_mesh

drawing_spec = mp_drawing.DrawingSpec(thickness=2, circle_radius=1, color=(4, 244, 4))

# Crea un oggetto mesh facciale
with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5) as face_mesh:

    # Leggo l'immagine con cv2
    image = cv2.imread(file)
    # Converto l'immagine da BGR a RGB
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    # Processo l'immagine
    results = face_mesh.process(image_rgb)

face_found = bool(results.multi_face_landmarks)

if face_found:
    # Creo una copia dell'immagine
    annotated_image = image.copy()

    # Inizializza un elenco vuoto per memorizzare tutti i punti
    all_landmarks = []

    # Disegna punti di riferimento e memorizza le loro posizioni
    for face_landmarks in results.multi_face_landmarks:
        mp_drawing.draw_landmarks(
            image=annotated_image,
            landmark_list=face_landmarks,
            connections=mp_face_mesh.FACEMESH_TESSELATION,
            landmark_drawing_spec=drawing_spec,
            connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=1)
        )

        # Memorizza i punti di riferimento in all_landmarks
        for landmark in face_landmarks.landmark:
            all_landmarks.append((landmark.x, landmark.y, landmark.z))

    # Salva l'immagine con i punti di riferimento
    cv2.imwrite('face_tesselation_only.png', annotated_image)

    # Visualizza l'immagine
    cv2_imshow(annotated_image)

if face_found:
  # Inizializza un elenco vuoto per memorizzare i punti di riferimento del centro degli occhi
  eye_landmarks = {'left': [], 'right': []}

  # Scorro ogni punto di riferimento del volto
  for face_landmarks in results.multi_face_landmarks:
      # Indici dei landmark dell'occhio sinistro
      left_eye_landmarks_indices = [474,475, 476, 477]
      # Indici dei landmark dell'occhio destro
      right_eye_landmarks_indices = [469, 470, 471, 472]

      # Disegno i landmark dell'occhio sinistro e li metto nella variabile eye_landmarks
      for i in left_eye_landmarks_indices:
          landmark = face_landmarks.landmark[i]
          eye_landmarks['left'].append((landmark.x, landmark.y))
          cv2.circle(image, (int(landmark.x * image.shape[1]), int(landmark.y * image.shape[0])), 2, (0, 255, 0), -1)

      # Disegno i landmark dell'occhio destro e li metto nella variabile eye_landmarks
      for i in right_eye_landmarks_indices:
          landmark = face_landmarks.landmark[i]
          eye_landmarks['right'].append((landmark.x, landmark.y))
          cv2.circle(image, (int(landmark.x * image.shape[1]), int(landmark.y * image.shape[0])), 2, (0, 255, 0), -1)

  # Visualizza l'immagine con i landmark dell'occhio
  cv2_imshow(image)
  print()
  
  # Stampa le coordinate dei landmark degli occhi
  print("Coordinate dei landmark dell'occhio sinistro:")
  print(eye_landmarks['left'])
  print()
  print("Coordinate dei landmark dell'occhio destro:")
  print(eye_landmarks['right'])

# Calcolo il baricentro dei 4 punti per ricavare il centro dell'occhio

# Calcola il baricentro per l'occhio sinistro
somma_x_left = sum(punto[0] for punto in eye_landmarks['left'])
somma_y_left = sum(punto[1] for punto in eye_landmarks['left'])
numero_punti_left = len(eye_landmarks['left'])
baricentro_x_left = somma_x_left / numero_punti_left
baricentro_y_left = somma_y_left / numero_punti_left

# Calcola il baricentro per l'occhio destro
somma_x_right = sum(punto[0] for punto in eye_landmarks['right'])
somma_y_right = sum(punto[1] for punto in eye_landmarks['right'])
numero_punti_right = len(eye_landmarks['right'])
baricentro_x_right = somma_x_right / numero_punti_right
baricentro_y_right = somma_y_right / numero_punti_right

baricentro_occhio_sinistro = (baricentro_x_left, baricentro_y_left)
baricentro_occhio_destro = (baricentro_x_right, baricentro_y_right)

print("Il baricentro dell'occhio sinistro è:", baricentro_occhio_sinistro)
print("Il baricentro dell'occhio destro è:", baricentro_occhio_destro)
