# Per prima cosa installo mediapipe
!pip install mediapipe

# Poi scarico i pacchetti dei modelli.
# Nella documentazione di MediaPipe vi sono ulteriori informazioni su questi bundle di modelli
!wget -O face_landmarker_v2_with_blendshapes.task -q https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task

# Qui importo tutto quello che mi serve

from mediapipe import solutions
import mediapipe as mp
from mediapipe.framework.formats import landmark_pb2
import numpy as np
import cv2
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow  # Questo mi serve per visualizzare l'immagine
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
from PIL import Image
from re import I
from google.colab import drive
import os

# Prendo l'immagine
drive.mount('/content/drive')

# Percorso del file su Google Drive
file = '/content/drive/MyDrive/Tirocinio/frame1.jpg'

# Creo la funzione draw_landmarks_on_image che mi disegna sull'immagine i landmark riconosciuti sull'iride
# La funzione ritorna l'immagine già con i landmark disegnati
def draw_landmarks_on_image(rgb_image, detection_result):
  face_landmarks_list = detection_result.face_landmarks
  annotated_image = np.copy(rgb_image)

  # Qui si passano in rassegna i volti rilevati nell'immagine per visualizzarli.
  for idx in range(len(face_landmarks_list)):
    face_landmarks = face_landmarks_list[idx]

    # Qui vengono disegnati i landmark sulle iridi
    face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()
    face_landmarks_proto.landmark.extend([ landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks ])

    solutions.drawing_utils.draw_landmarks(
        image=annotated_image,
        landmark_list=face_landmarks_proto,
        connections=mp.solutions.face_mesh.FACEMESH_IRISES,
          landmark_drawing_spec=None,
          connection_drawing_spec=mp.solutions.drawing_styles
          .get_default_face_mesh_iris_connections_style())

  return annotated_image

# Successivamente, inizio con i passaggi per il riconoscimento dei landmark
# Passaggio 1 --> Crea un oggetto FaceLandmarker
base_options = python.BaseOptions(model_asset_path='face_landmarker_v2_with_blendshapes.task')
options = vision.FaceLandmarkerOptions(base_options=base_options,
                                       output_face_blendshapes=True,
                                       output_facial_transformation_matrixes=True,
                                       num_faces=1)
detector = vision.FaceLandmarker.create_from_options(options)

# Passaggio 2 --> Carica una immagine in input
image = mp.Image.create_from_file(file)

# Passaggio 3 --> Rileva tutti i punti di riferimento del viso dall'immagine data in input
detection_result = detector.detect(image)

# Passaggio 4 --> Elaborare il risultato del rilevamento, per poi visualizzarlo
annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)
cv2_imshow(cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))

mp_drawing = mp.solutions.drawing_utils
mp_face_mesh = mp.solutions.face_mesh

drawing_spec = mp_drawing.DrawingSpec(thickness=2, circle_radius=1, color=(4, 244, 4))

# Crea un oggetto mesh facciale
with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5) as face_mesh:

    # Leggo l'immagine con cv2
    image = cv2.imread(file)
    # Converto l'immagine da BGR a RGB
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    # Processo l'immagine
    results = face_mesh.process(image_rgb)

face_found = bool(results.multi_face_landmarks)

if face_found:
    # Creo una copia dell'immagine
    annotated_image = image.copy()

    # Inizializza un elenco vuoto per memorizzare tutti i punti
    all_landmarks = []

    # Disegna punti di riferimento e memorizza le loro posizioni
    for face_landmarks in results.multi_face_landmarks:
        mp_drawing.draw_landmarks(
            image=annotated_image,
            landmark_list=face_landmarks,
            connections=mp_face_mesh.FACEMESH_TESSELATION,
            landmark_drawing_spec=drawing_spec,
            connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=1)
        )

        # Memorizza i punti di riferimento in all_landmarks
        for landmark in face_landmarks.landmark:
            all_landmarks.append((landmark.x, landmark.y, landmark.z))

    # Salva l'immagine con i punti di riferimento
    cv2.imwrite('face_tesselation_only.png', annotated_image)

    # Visualizza l'immagine
    cv2_imshow(annotated_image)

if face_found:
  # Inizializza un elenco vuoto per memorizzare i punti di riferimento del centro degli occhi
  eye_landmarks = {'left': [], 'right': []}

  # Scorro ogni punto di riferimento del volto
  for face_landmarks in results.multi_face_landmarks:
      # Indici dei landmark dell'occhio sinistro
      left_eye_landmarks_indices = [474,475, 476, 477]
      # Indici dei landmark dell'occhio destro
      right_eye_landmarks_indices = [469, 470, 471, 472]

      # Disegno i landmark dell'occhio sinistro e li metto nella variabile eye_landmarks
      for i in left_eye_landmarks_indices:
          landmark = face_landmarks.landmark[i]
          eye_landmarks['left'].append((landmark.x, landmark.y))
          cv2.circle(image, (int(landmark.x * image.shape[1]), int(landmark.y * image.shape[0])), 2, (0, 255, 0), -1)

      # Disegno i landmark dell'occhio destro e li metto nella variabile eye_landmarks
      for i in right_eye_landmarks_indices:
          landmark = face_landmarks.landmark[i]
          eye_landmarks['right'].append((landmark.x, landmark.y))
          cv2.circle(image, (int(landmark.x * image.shape[1]), int(landmark.y * image.shape[0])), 2, (0, 255, 0), -1)

  # Visualizza l'immagine con i landmark dell'occhio
  cv2_imshow(image)
  print()
  
  # Stampa le coordinate dei landmark degli occhi
  print("Coordinate dei landmark dell'occhio sinistro:")
  print(eye_landmarks['left'])
  print()
  print("Coordinate dei landmark dell'occhio destro:")
  print(eye_landmarks['right'])

# Calcolo il baricentro dei 4 punti per ricavare il centro dell'occhio

# Calcola il baricentro per l'occhio sinistro
somma_x_left = sum(punto[0] for punto in eye_landmarks['left'])
somma_y_left = sum(punto[1] for punto in eye_landmarks['left'])
numero_punti_left = len(eye_landmarks['left'])
baricentro_x_left = somma_x_left / numero_punti_left
baricentro_y_left = somma_y_left / numero_punti_left

# Calcola il baricentro per l'occhio destro
somma_x_right = sum(punto[0] for punto in eye_landmarks['right'])
somma_y_right = sum(punto[1] for punto in eye_landmarks['right'])
numero_punti_right = len(eye_landmarks['right'])
baricentro_x_right = somma_x_right / numero_punti_right
baricentro_y_right = somma_y_right / numero_punti_right

baricentro_occhio_sinistro = (baricentro_x_left, baricentro_y_left)
baricentro_occhio_destro = (baricentro_x_right, baricentro_y_right)

print("Il baricentro dell'occhio sinistro è:", baricentro_occhio_sinistro)
print("Il baricentro dell'occhio destro è:", baricentro_occhio_destro)

# Per aiutarci nel ritaglio dell'immagine, serve convertire le coordinate di essa in px

# Per prima cosa ricarichiamo la stessa immagine, in image_test utilizzando OpenCV e non Mediapipe
image_test = cv2.imread(file)
# Prendendo l'immagine con OpenCV avremo le sue dimensioni in px

if image_test is not None:
    # Ottengo le dimensioni dell'immagine
    height, width, channels = image_test.shape

    print("Larghezza dell'immagine:", width)
    print("Altezza dell'immagine:", height)
else:
    print("Impossibile caricare l'immagine.")

# Creo una lista destro, che conterrà tutte le coordinate dei landmarks trovati dell'occhio destro, convertite in px
destro = []
destro.append((int(eye_landmarks['right'][0][0] * width), int(eye_landmarks['right'][0][1] * height)))
destro.append((int(eye_landmarks['right'][1][0] * width), int(eye_landmarks['right'][1][1] * height)))
destro.append((int(eye_landmarks['right'][2][0] * width), int(eye_landmarks['right'][2][1] * height)))
destro.append((int(eye_landmarks['right'][3][0] * width), int(eye_landmarks['right'][3][1] * height)))

# Creo una lista sinistro, che conterrà tutte le coordinate dei landmarks trovati dell'occhio sinistro, convertite in px
sinistro = []
sinistro.append((int(eye_landmarks['left'][0][0] * width), int(eye_landmarks['left'][0][1] * height)))
sinistro.append((int(eye_landmarks['left'][1][0] * width), int(eye_landmarks['left'][1][1] * height)))
sinistro.append((int(eye_landmarks['left'][2][0] * width), int(eye_landmarks['left'][2][1] * height)))
sinistro.append((int(eye_landmarks['left'][3][0] * width), int(eye_landmarks['left'][3][1] * height)))

print("Coordinate punti occhio destro: ", destro)
print("Coordinate punti occhio sinistro: ", sinistro)

# Ora voglio convertire anche i punti del centro dell'occhio
centro_destro = []
centro_destro.append((int(baricentro_occhio_destro[0] * width), int(baricentro_occhio_destro[1] * height)))
print(centro_destro)

# Lascio commentata questa parte di codice, l'ho usato solo per controllare dove fosse il baricentro dell'occhio destro che ho trovato
#cv2.circle(image_test, (centro_destro[0][0], centro_destro[0][1]), 1, (0, 255, 0), 1)
#cv2_imshow(image_test)

centro_sinistro = []
centro_sinistro.append((int(baricentro_occhio_sinistro[0] * width), int(baricentro_occhio_sinistro[1] * height)))
print(centro_sinistro)

# Lascio commentata questa parte di codice, l'ho usato solo per controllare dove fosse il baricentro dell'occhio sinistro che ho trovato
#cv2.circle(image_test, (centro_sinistro[0][0], centro_sinistro[0][1]), 1, (0, 0, 255), 1)
#cv2_imshow(image_test)

# Creo un rettangolo per ogni occhio, utilizzo i 4 punti di ogni occhio e le loro coordinate
cv2.rectangle(image_test, (destro[2][0], destro[1][1]), (destro[0][0], destro[3][1]), (0, 255, 0), 2)
cv2.rectangle(image_test, (sinistro[2][0], sinistro[1][1]), (sinistro[0][0], sinistro[3][1]), (0, 0, 255), 2)
cv2_imshow(image_test)

# Ora ritaglio i due occhi e salvo queste due immagini
occhio_destro = image_test[destro[1][1]:destro[3][1], destro[2][0]:destro[0][0]]
cv2_imshow(occhio_destro)
print()
occhio_sinistro = image_test[sinistro[1][1]:sinistro[3][1], sinistro[2][0]:sinistro[0][0]]
cv2_imshow(occhio_sinistro)

# Siccome le immagini degli occhi, le ingrandisco utilizzando resize()
# Definisco il fattore di ingrandimento
fattore_ingrandimento = 7  # Puoi cambiare questo valore a seconda della dimensione desiderata

# Applichiamo il ridimensionamento all'occhio destro e lo stampiamo
destro = cv2.resize(occhio_destro, (occhio_destro.shape[1] * fattore_ingrandimento, occhio_destro.shape[0] * fattore_ingrandimento))
cv2_imshow(destro)
#destro.save("/content/drive/MyDrive/Tirocinio/occhio-destro.jpg")

# Salvo ora l'immagine nella cartella output del drive, utilizzando imsave, importato da skimage.io 
imsave("/content/drive/MyDrive/Tirocinio/Output/occhio-destro.jpg", destro)
print()

# Applichiamo il ridimensionamento all'occhio destro e lo stampiamo
sinistro = cv2.resize(occhio_sinistro, (occhio_sinistro.shape[1] * fattore_ingrandimento, occhio_sinistro.shape[0] * fattore_ingrandimento))
cv2_imshow(sinistro)
imsave("/content/drive/MyDrive/Tirocinio/Output/occhio-sinistro.jpg", sinistro)
